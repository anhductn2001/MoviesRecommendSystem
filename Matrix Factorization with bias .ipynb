{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 100 , loss = 0.6771573758208562 , RMSE train = 0.6459393234199525\n",
      "iter = 200 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 300 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 400 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 500 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 600 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 700 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 800 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 900 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "iter = 1000 , loss = 0.6771573758208117 , RMSE train = 0.6459393234200664\n",
      "0.6459393234200664\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "\n",
    "class MF(object):\n",
    "    \"\"\"docstring for CF\"\"\"\n",
    "    def __init__(self, Y_data, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "                 learning_rate = 0.5, max_iter = 1000, print_every = 100, user_based = 0):\n",
    "        self.Y_raw = Y_data.copy()\n",
    "        self.Y_data = Y_data.copy()\n",
    "        self.K = K\n",
    "        self.lam = lam\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.print_every = print_every\n",
    "        self.user_based = user_based\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = int(np.max(Y_data[:, 0])) + 1 \n",
    "        self.n_items = int(np.max(Y_data[:, 1])) + 1\n",
    "        \n",
    "        if Xinit is None: \n",
    "            self.X = np.random.randn(self.n_items, K)\n",
    "        else:\n",
    "            self.X = Xinit \n",
    "        \n",
    "        if Winit is None: \n",
    "            self.W = np.random.randn(K, self.n_users)\n",
    "        else: \n",
    "            self.W = Winit\n",
    "        \n",
    "        # item biases\n",
    "        self.b = np.random.randn(self.n_items)\n",
    "        self.d = np.random.randn(self.n_users)\n",
    "        #self.all_users = self.Y_data[:,0] # all users (may be duplicated)\n",
    "        self.n_ratings = Y_data.shape[0]\n",
    "#         self.mu = np.mean(Y_data[:, 2])\n",
    "        self.mu = 0\n",
    " \n",
    "\n",
    "    def normalize_Y(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.n_users\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.n_items\n",
    "        self.muu = np.zeros(n_objects)\n",
    "        self.Y_data = self.Y_raw\n",
    "        return\n",
    "    \n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.n_users\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.n_items\n",
    "\n",
    "        users = self.Y_data[:, user_col] \n",
    "        self.muu = np.zeros((n_objects,))\n",
    "        for n in range(n_objects):\n",
    "            # row indices of rating done by user n\n",
    "            # since indices need to be integers, we need to convert\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            # indices of all ratings associated with user n\n",
    "            item_ids = self.Y_data[ids, item_col] \n",
    "            # and the corresponding ratings \n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            # take mean\n",
    "            m = np.mean(ratings) \n",
    "\n",
    "            if np.isnan(m):\n",
    "                m = 0 # to avoid empty array and nan value\n",
    "            self.muu[n] = m\n",
    "            # normalize\n",
    "            self.Y_data[ids, 2] = ratings - m\n",
    "            \n",
    "            \n",
    "    def loss(self):\n",
    "        L = 0 \n",
    "        for i in range(self.n_ratings):\n",
    "            # user, item, rating\n",
    "            n, m, rate = int(self.Y_data[i, 0]), int(self.Y_data[i, 1]), self.Y_data[i, 2]\n",
    "            L += 0.5*(self.X[m, :].dot(self.W[:, n]) + self.b[m] + self.d[n] + self.mu - rate)**2\n",
    "            \n",
    "        # regularization, don't ever forget this \n",
    "        L /= self.n_ratings\n",
    "        L += 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "#         L += 0.5*self.lam*(np.linalg.norm(self.X, 'fro')**2 + np.linalg.norm(self.W, 'fro')**2 + \\\n",
    "#                           np.linalg.norm(self.b) + np.linalg.norm(self.d))\n",
    "        return L \n",
    "\n",
    "    \n",
    "    def get_items_rated_by_user(self, user_id):\n",
    "        \"\"\"\n",
    "        get all items which are rated by user n, and the corresponding ratings\n",
    "        \"\"\"\n",
    "        # y = self.Y_data_n[:,0] # all users (may be duplicated)\n",
    "        # item indices rated by user_id\n",
    "        # we need to +1 to user_id since in the rate_matrix, id starts from 1 \n",
    "        # while index in python starts from 0\n",
    "        ids = np.where(self.Y_data[:,0] == user_id)[0] \n",
    "        item_ids = self.Y_data[ids, 1].astype(np.int32) # index starts from 0 \n",
    "        ratings = self.Y_data[ids, 2]\n",
    "        return (item_ids, ratings)\n",
    "        \n",
    "        \n",
    "    def get_users_who_rate_item(self, item_id):\n",
    "        \"\"\"\n",
    "        get all users who rated item m and get the corresponding ratings\n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:,1] == item_id)[0] \n",
    "        user_ids = self.Y_data[ids, 0].astype(np.int32)\n",
    "        ratings = self.Y_data[ids, 2]\n",
    "        return (user_ids, ratings)\n",
    "        \n",
    "    def updateX(self): # and b \n",
    "\n",
    "            for m in range(self.n_items):\n",
    "                user_ids, ratings = self.get_users_who_rate_item(m)\n",
    "\n",
    "                Wm = self.W[:, user_ids]\n",
    "                dm = self.d[user_ids]\n",
    "                for i in range(30):\n",
    "                    xm = self.X[m, :]\n",
    "\n",
    "                    error = xm.dot(Wm) + self.b[m] + dm + self.mu - ratings \n",
    "\n",
    "                    grad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\n",
    "                    grad_bm = np.sum(error)/self.n_ratings# + self.lam*self.b[m]\n",
    "                    self.X[m, :] -= self.learning_rate*grad_xm.reshape(-1)\n",
    "                    self.b[m]    -= self.learning_rate*grad_bm\n",
    "    \n",
    "    def updateW(self): # and d \n",
    "            for n in range(self.n_users):\n",
    "                item_ids, ratings = self.get_items_rated_by_user(n)\n",
    "                Xn = self.X[item_ids, :]\n",
    "                bn = self.b[item_ids]\n",
    "                for i in range(30):\n",
    "                    wn = self.W[:, n]\n",
    "                    error = Xn.dot(wn) + bn + self.mu + self.d[n] - ratings\n",
    "                    grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                    grad_dn = np.sum(error)/self.n_ratings# + self.lam*self.d[n]\n",
    "                    self.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\n",
    "                    self.d[n]    -= self.learning_rate*grad_dn\n",
    "    \n",
    "    def fit(self):\n",
    "        self.normalize_Y()\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateW()\n",
    "            self.updateX()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y_raw)\n",
    "                print ('iter =', it + 1, ', loss =', self.loss(), ', RMSE train =', rmse_train)\n",
    "    \n",
    "    \n",
    "    def pred(self, u, i):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i \n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based == 1:\n",
    "            bias = self.muu[u]\n",
    "        else:\n",
    "            bias = self.muu[i]\n",
    "        \n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u] + bias\n",
    "        return max(0, min(5, pred))\n",
    "        \n",
    "    \n",
    "    def pred_for_user(self, user_id):\n",
    "        ids = np.where(self.Y_data_n[:, 0] == user_id)[0]\n",
    "        items_rated_by_u = self.Y_data_n[ids, 1].tolist()              \n",
    "        \n",
    "        y_pred = self.X.dot(self.W[:, user_id])\n",
    "        predicted_ratings= []\n",
    "        for i in range(self.n_items):\n",
    "            if i not in items_rated_by_u:\n",
    "                predicted_ratings.append((i, y_pred[i]))\n",
    "        \n",
    "        return predicted_ratings\n",
    "    \n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "#             print pred, rate_test[n, 2]\n",
    "            SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "        \n",
    "r_cols = ['user_id', 'item_id', 'rating']\n",
    "ratings = pd.read_csv('ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "Y_data = ratings[r_cols].values\n",
    "\n",
    "\n",
    "rs = MF(Y_data, K = 3, max_iter = 1000, print_every = 100, lam = 0.1)\n",
    "\n",
    "rs.fit()\n",
    "rs.pred(6, 1)\n",
    "print (rs.evaluate_RMSE(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Áp dụng lên MovieLens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base[r_cols].values\n",
    "rate_test = ratings_test[r_cols].values\n",
    "\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 1 , loss = 0.818103902724614 , RMSE train = 1.225483635870316\n",
      "iter = 2 , loss = 0.5464814343455631 , RMSE train = 1.0443471441048047\n",
      "iter = 3 , loss = 0.4857952426419337 , RMSE train = 0.9852527009697586\n",
      "iter = 4 , loss = 0.4585134576241089 , RMSE train = 0.9573192380457018\n",
      "iter = 5 , loss = 0.44384368332279084 , RMSE train = 0.9419068885175774\n",
      "iter = 6 , loss = 0.43512619215278175 , RMSE train = 0.9326276930733748\n",
      "iter = 7 , loss = 0.4295981769839635 , RMSE train = 0.9266985277945321\n",
      "iter = 8 , loss = 0.4259244099940175 , RMSE train = 0.9227381224068802\n",
      "iter = 9 , loss = 0.4233918071110596 , RMSE train = 0.9199981879446365\n",
      "iter = 10 , loss = 0.4215920258321279 , RMSE train = 0.9180460588392063\n",
      "iter = 11 , loss = 0.42027888531838353 , RMSE train = 0.9166191604289436\n",
      "iter = 12 , loss = 0.4192979575973349 , RMSE train = 0.915548978737078\n",
      "iter = 13 , loss = 0.4185492426500177 , RMSE train = 0.9147308084701189\n",
      "iter = 14 , loss = 0.4179662640673648 , RMSE train = 0.9140913941884442\n",
      "iter = 15 , loss = 0.41750383643722283 , RMSE train = 0.9135835869848498\n",
      "iter = 16 , loss = 0.4171306460896705 , RMSE train = 0.9131731122493418\n",
      "iter = 17 , loss = 0.4168246151401883 , RMSE train = 0.9128360780427653\n",
      "iter = 18 , loss = 0.4165699309960238 , RMSE train = 0.9125554395540272\n",
      "iter = 19 , loss = 0.41635510175673385 , RMSE train = 0.9123183202000765\n",
      "iter = 20 , loss = 0.4161716594093912 , RMSE train = 0.9121158848867502\n",
      "iter = 21 , loss = 0.41601328090029854 , RMSE train = 0.9119411782733298\n",
      "iter = 22 , loss = 0.4158751838125998 , RMSE train = 0.9117889322937103\n",
      "iter = 23 , loss = 0.41575370545095564 , RMSE train = 0.9116550985382619\n",
      "iter = 24 , loss = 0.41564600618949726 , RMSE train = 0.9115365089992306\n",
      "iter = 25 , loss = 0.41554985809494954 , RMSE train = 0.9114305877934797\n",
      "iter = 26 , loss = 0.41546349274881056 , RMSE train = 0.9113354166672496\n",
      "iter = 27 , loss = 0.4153854906027149 , RMSE train = 0.91124933596543\n",
      "iter = 28 , loss = 0.41531469975966373 , RMSE train = 0.9111712619075971\n",
      "iter = 29 , loss = 0.41525017579566786 , RMSE train = 0.9111001414434223\n",
      "iter = 30 , loss = 0.4151911367586709 , RMSE train = 0.911035103463027\n",
      "\n",
      "User-based MF, RMSE = 0.9626638755376513\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 1, learning_rate = 50, max_iter = 30, user_based = 0)\n",
    "rs.fit()\n",
    "# evaluate on test data\n",
    "RMSE = rs.evaluate_RMSE(rate_test)\n",
    "print ('\\nUser-based MF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.87425574, 2.90956755, 2.43575752, 3.82127687, 2.42677735,\n",
       "       2.58096518, 3.24403773, 3.09404566, 3.22352365, 3.17547943,\n",
       "       2.71956369, 3.32369678, 2.5457139 , 3.08876842, 2.3977117 ,\n",
       "       3.43923084, 2.37490832, 2.87583698, 2.82483003, 2.41485799,\n",
       "       2.47121093, 2.81919494, 2.69991841, 3.39214434, 2.9044119 ,\n",
       "       2.34770837, 2.66461924, 2.96983299, 3.03691808, 3.16362412,\n",
       "       2.91628881, 2.576128  , 3.35957238, 3.43817998, 2.72372968,\n",
       "       3.84658115, 3.03286887, 3.37514902, 3.11107059, 2.06389422,\n",
       "       2.6922867 , 2.99235442, 2.98698215, 2.77744451, 3.16655642,\n",
       "       3.26169598, 2.91086625, 2.65446019, 2.08925183, 2.87339138,\n",
       "       2.46971884, 3.45886805, 3.15912036, 3.12660553, 2.93579076,\n",
       "       3.01185858, 2.9940798 , 2.85551577, 3.12004642, 3.06299186,\n",
       "       2.06803789, 2.52662237, 2.39935912, 2.68955285, 2.96802987,\n",
       "       2.77852747, 3.34947892, 2.4296392 , 2.96067046, 2.72533759,\n",
       "       2.53512482, 2.85349175, 2.68191118, 2.9110876 , 2.88835357,\n",
       "       2.58964126, 2.46377482, 2.91190159, 3.19379089, 2.76941805,\n",
       "       2.72759091, 2.37388755, 2.9545115 , 3.07501925, 2.60160335,\n",
       "       3.04144198, 3.20451479, 3.47615065, 3.228752  , 3.23058611,\n",
       "       2.91337404, 2.71073781, 2.10990223, 2.98630577, 2.71497952,\n",
       "       3.01486662, 2.90651843, 2.78949732, 3.00513442, 2.6204181 ,\n",
       "       2.5810969 , 2.02138949, 2.6647754 , 2.11957108, 2.41816053,\n",
       "       2.78969644, 2.18907566, 2.94262388, 2.89160063, 2.61484523,\n",
       "       2.67973604, 3.12789615, 3.00804229, 2.35993876, 2.92358079,\n",
       "       2.3369071 , 3.32806388, 3.74672531, 3.26241422, 2.73244184,\n",
       "       2.72787471, 2.99617639, 2.72728244, 2.28861191, 2.81204456,\n",
       "       3.0147154 , 3.74687253, 2.82098702, 1.93332084, 3.55770356,\n",
       "       3.16115754, 2.42934046, 2.47650033, 2.99790342, 2.7632802 ,\n",
       "       3.34916945, 3.66398118, 3.11733319, 3.04910917, 3.06348121,\n",
       "       2.97717847, 2.78999568, 2.92875635, 2.76688639, 2.95214794,\n",
       "       2.97073447, 3.472633  , 3.00054475, 2.28066047, 3.24507563,\n",
       "       3.0670713 , 3.74409418, 2.08722736, 2.90912126, 2.11551134,\n",
       "       2.54345223, 3.2658761 , 3.0679674 , 3.12889696, 3.03703319,\n",
       "       1.5286723 , 2.823588  , 2.09691142, 3.67396051, 2.99838025,\n",
       "       2.93080501, 2.7587012 , 2.84155465, 2.97024387, 3.34987063,\n",
       "       2.54641364, 2.02151779, 3.65734477, 3.10027777, 2.77958547,\n",
       "       3.02066984, 2.7533964 , 2.96946544, 2.30970014, 3.1286033 ,\n",
       "       1.27290396, 2.91466457, 2.54499055, 2.81341829, 2.9280428 ,\n",
       "       2.93160328, 3.0106445 , 2.91214079, 2.98238829, 2.81399767,\n",
       "       2.86744161, 2.70876379, 2.57924228, 2.19207241, 2.71954968,\n",
       "       2.69001429, 2.67220108, 2.42140184, 2.38228931, 3.44784104,\n",
       "       2.28155847, 1.44189728, 2.78393292, 2.71069065, 2.24169196,\n",
       "       1.61135762, 2.47366124, 2.83137   , 2.52463324, 3.14877592,\n",
       "       2.46246786, 2.93601052, 3.37174495, 2.85229194, 2.7438642 ,\n",
       "       2.97572966, 2.40987256, 2.58735969, 3.18547481, 3.1978731 ,\n",
       "       2.9548783 , 2.56871644, 2.6828792 , 2.39950052, 3.44881235,\n",
       "       2.72390314, 2.71255146, 2.16229042, 2.39665175, 2.91285588,\n",
       "       2.95655679, 2.78360271, 3.28251784, 2.26894391, 2.86354532,\n",
       "       2.51476034, 2.81549126, 2.82126723, 3.07261083, 2.99133533,\n",
       "       2.67246458, 3.55021339, 2.75669713, 3.048343  , 2.96493905,\n",
       "       2.39810311, 2.94671998, 2.58454874, 3.23514996, 3.0452    ,\n",
       "       3.01133401, 3.67348836, 3.01077903, 2.48279599, 2.32653535,\n",
       "       3.56552451, 3.12143603, 3.24843131, 3.08237159, 3.69686747,\n",
       "       3.73678865, 2.46325184, 3.03419807, 3.366729  , 3.09165764,\n",
       "       2.38093518, 3.2630633 , 2.4111733 , 2.21450191, 3.6879495 ,\n",
       "       2.6771587 , 3.17592259, 2.52576496, 3.35291515, 2.33077022,\n",
       "       2.95968786, 2.65748689, 3.22792222, 2.81638257, 3.0063623 ,\n",
       "       2.83383315, 2.85901669, 3.34083568, 2.95297778, 2.79233492,\n",
       "       3.10673871, 3.31608072, 2.86933281, 2.22834966, 2.62509736,\n",
       "       3.24596084, 3.19244002, 2.28273804, 3.06232383, 3.49733702,\n",
       "       3.15080483, 2.56842193, 3.09069011, 2.58378289, 3.42209074,\n",
       "       2.86588637, 2.33333681, 2.84358328, 2.8413618 , 2.40840319,\n",
       "       2.83498719, 2.95026737, 2.87395439, 3.17799176, 2.80381374,\n",
       "       3.00312343, 3.27124202, 2.74906515, 3.3161645 , 3.05685822,\n",
       "       2.20289288, 3.33669478, 2.98558733, 2.80056412, 3.25125597,\n",
       "       2.58579846, 2.8799468 , 2.87534939, 3.77660587, 2.49346248,\n",
       "       2.39062961, 2.4325929 , 2.71214174, 2.45030866, 3.70128457,\n",
       "       2.68256733, 3.65903823, 2.70578845, 2.69638176, 2.97161456,\n",
       "       2.62922282, 3.29406339, 2.9228068 , 3.14506011, 3.0219049 ,\n",
       "       3.8828587 , 2.62738633, 3.1526475 , 2.82891738, 2.91811264,\n",
       "       2.69312198, 2.8822312 , 3.55861722, 2.81358272, 3.11010634,\n",
       "       3.77597039, 2.7528378 , 2.47471697, 2.72373419, 3.78240985,\n",
       "       2.71434281, 3.8399794 , 2.78871377, 3.27195293, 2.89156495,\n",
       "       2.84681171, 3.00754757, 2.36458758, 3.17912994, 2.7521474 ,\n",
       "       3.79187686, 3.63811507, 2.74671191, 3.33798843, 2.5780032 ,\n",
       "       3.09606713, 3.69342433, 2.92500617, 2.77889358, 3.11371755,\n",
       "       2.621107  , 3.22694143, 2.78607837, 3.10067735, 2.19122518,\n",
       "       2.96463446, 2.62517049, 3.22029024, 3.41507693, 2.34280503,\n",
       "       3.35109996, 2.54220067, 3.58945938, 2.86224664, 2.89901307,\n",
       "       2.72850253, 3.07376069, 2.91011272, 3.25770684, 3.0608163 ,\n",
       "       2.99070744, 2.8483988 , 2.75748743, 2.3854582 , 2.85738227,\n",
       "       2.21900755, 2.95953369, 3.00839912, 2.78377023, 1.39476505,\n",
       "       2.64233636, 2.65349298, 3.12535935, 2.62473477, 2.49031572,\n",
       "       2.76358525, 2.89861237, 2.87426068, 3.36193577, 3.19903334,\n",
       "       3.25962743, 2.69158229, 2.31379536, 2.95119626, 3.04174686,\n",
       "       2.69537533, 2.87982334, 2.91067744, 2.61677874, 2.34302668,\n",
       "       2.62704343, 4.12792662, 3.46631538, 2.65199861, 2.58217576,\n",
       "       2.76586729, 3.05874379, 2.605782  , 3.26975581, 2.75203825,\n",
       "       3.15518448, 2.72721038, 3.43975598, 2.94851494, 3.54373748,\n",
       "       3.00304106, 2.5419293 , 2.66394739, 2.85159924, 1.31437193,\n",
       "       2.41491941, 2.84524743, 2.56059185, 2.96343407, 3.17138456,\n",
       "       2.54637006, 2.51401601, 2.66559026, 2.04837292, 2.68283043,\n",
       "       2.69490277, 3.34967226, 2.71991097, 2.93523405, 2.60192045,\n",
       "       2.52002002, 3.3847444 , 2.32898985, 3.30237355, 2.29384923,\n",
       "       2.76622814, 2.83875431, 3.08974512, 3.35289338, 2.80703201,\n",
       "       2.89276526, 3.78685339, 2.95965936, 3.11448146, 2.25273162,\n",
       "       2.82170896, 3.9827179 , 2.64680997, 2.59417839, 2.51259153,\n",
       "       3.0236776 , 2.66436801, 2.2754724 , 3.23252994, 2.36308325,\n",
       "       2.64503123, 2.98194273, 2.38111841, 3.51018302, 2.13099072,\n",
       "       2.59938762, 2.30318217, 2.8862841 , 2.87347542, 3.32784261,\n",
       "       2.29163511, 2.6945091 , 2.27660635, 2.83184104, 2.65263814,\n",
       "       3.18905267, 3.01365872, 3.05602337, 3.01833473, 2.53358281,\n",
       "       2.91528558, 4.1515361 , 2.81359785, 2.00556064, 2.84127345,\n",
       "       3.67829461, 3.39217687, 3.84993794, 2.87812459, 2.54836482,\n",
       "       3.01790926, 2.67055114, 3.22743287, 3.693601  , 2.86865357,\n",
       "       2.35761648, 3.20910116, 3.55428781, 2.65318517, 2.66170592,\n",
       "       2.47401114, 2.71182732, 2.89451627, 3.24603039, 2.9132522 ,\n",
       "       3.000001  , 3.56268778, 2.61904895, 3.72237256, 2.92722364,\n",
       "       3.01311966, 2.03940754, 2.51658181, 2.86877187, 3.08531768,\n",
       "       3.05458144, 2.7028415 , 2.65231662, 2.26899339, 2.87759034,\n",
       "       3.48395583, 2.8900923 , 2.99047332, 3.07451026, 3.30159037,\n",
       "       3.1937295 , 2.63720414, 2.98450917, 2.81755804, 3.27330153,\n",
       "       3.04785085, 3.04241442, 2.89085122, 2.64823021, 2.67699492,\n",
       "       2.18879734, 2.57364792, 3.1859623 , 2.80326442, 3.32644617,\n",
       "       2.63189818, 2.79381861, 2.18435414, 2.81957048, 2.1443332 ,\n",
       "       1.9921095 , 2.56577281, 2.56853937, 2.77798966, 2.09597012,\n",
       "       2.63894863, 3.16112199, 2.14737765, 2.55145415, 3.07634341,\n",
       "       3.11340742, 2.71553937, 3.49680133, 2.97678125, 2.79764263,\n",
       "       2.74341295, 2.69896145, 3.08245712, 3.1171336 , 2.62720305,\n",
       "       2.70174645, 3.09724536, 2.88416027, 2.5511698 , 2.78284521,\n",
       "       2.976755  , 3.06315718, 2.89372492, 3.51645442, 3.02982323,\n",
       "       2.31590199, 3.27338785, 3.00783291, 2.69824907, 2.90095775,\n",
       "       3.17727841, 2.74437654, 2.68279421, 2.00997349, 2.63513426,\n",
       "       3.15738887, 2.65161398, 3.28638459, 2.73916088, 2.94909078,\n",
       "       3.00490147, 1.94574225, 2.44615686, 2.89633957, 3.43399328,\n",
       "       3.11726439, 2.75782278, 2.68148917, 2.96791332, 2.40455123,\n",
       "       1.87373835, 2.53012315, 3.99041139, 3.16501361, 2.73504777,\n",
       "       2.4683411 , 2.73233318, 2.51691092, 2.81662555, 2.73160665,\n",
       "       3.7341499 , 1.88516424, 2.63048471, 1.91697658, 3.45221218,\n",
       "       2.97912822, 3.27591362, 2.90507106, 3.53240861, 2.90684602,\n",
       "       2.57851167, 3.05803061, 2.71430739, 3.1672234 , 2.36651806,\n",
       "       2.54511603, 2.54040385, 2.03681235, 2.87811383, 2.18972519,\n",
       "       1.80667023, 2.31617482, 2.66976949, 2.81593696, 1.95204045,\n",
       "       2.90005331, 3.39443633, 2.85337341, 2.76082425, 2.74245618,\n",
       "       2.69582367, 2.85234565, 2.86644698, 2.34539078, 2.68889404,\n",
       "       2.9604273 , 2.6527208 , 2.86932837, 2.98989607, 2.56710082,\n",
       "       2.80845569, 3.28985506, 2.44657998, 2.70032606, 3.0512885 ,\n",
       "       2.77281189, 2.57979321, 2.62293035, 2.86536788, 1.6806608 ,\n",
       "       3.39827704, 2.8996149 , 4.67896353, 3.22713757, 2.47754189,\n",
       "       3.34715814, 2.76324939, 2.19838713, 3.12086713, 2.76128518,\n",
       "       2.92053956, 3.24372035, 1.70251411, 2.6305884 , 2.33338552,\n",
       "       3.27022237, 2.09864486, 2.89319113, 2.68899197, 3.05990945,\n",
       "       2.8178483 , 2.64282209, 2.82293517, 2.9522022 , 2.69285069,\n",
       "       3.06449004, 3.15276011, 2.11468711, 3.05597041, 2.70961857,\n",
       "       2.94581335, 3.10548496, 3.39328015, 2.22991333, 3.17249838,\n",
       "       2.97565328, 3.21272434, 2.45042804, 1.85622159, 3.50722262,\n",
       "       2.67144111, 2.54136781, 2.86215571, 2.20470697, 2.38808821,\n",
       "       2.34187411, 3.56749858, 2.40919452, 2.54561931, 2.49029925,\n",
       "       2.19248804, 2.7423192 , 2.7642343 , 2.34560314, 2.61137018,\n",
       "       2.69118082, 2.76291123, 2.93183445, 2.65251147, 1.80437096,\n",
       "       2.80021987, 3.13975721, 2.62430354, 2.98058916, 2.61563063,\n",
       "       2.70586124, 2.66333486, 2.4020273 , 2.68411086, 2.57842155,\n",
       "       2.4893121 , 2.71682115, 3.1774074 , 3.28675302, 2.95526374,\n",
       "       2.33651869, 1.56193442, 2.87334909, 3.02651074, 3.08339708,\n",
       "       2.43690103, 3.31355214, 2.5816378 , 2.80883124, 3.60037465,\n",
       "       2.78327316, 3.38789035, 2.47530552, 1.46108364, 3.07752908,\n",
       "       2.74143539, 3.35623728, 2.1177061 , 3.34999726, 2.83517602,\n",
       "       2.65483155, 2.50761193, 3.41541526, 3.2426288 , 2.70848485,\n",
       "       2.9838076 , 2.58017762, 2.64826946, 2.71789116, 2.48182247,\n",
       "       3.21840693, 2.57484072, 2.86470213, 3.27228598, 2.51197682,\n",
       "       2.95165168, 2.23940108, 2.90371589, 3.04144683, 3.15336321,\n",
       "       3.51841554, 3.12428395, 2.7994214 , 3.02112923, 2.71760476,\n",
       "       2.78649565, 3.22398992, 3.64449277, 2.66675045, 4.08628751,\n",
       "       3.90004453, 3.14258506, 2.87637422, 2.54695342, 2.84794212,\n",
       "       3.71082308, 2.79496413, 2.73186002, 3.20317754, 2.45198808,\n",
       "       3.43221264, 2.54610001, 3.12603167, 2.24043667, 3.27604962,\n",
       "       3.21155055, 2.67713104, 2.19816945, 2.68916749, 2.87957681,\n",
       "       2.65994462, 2.51699145, 2.32647395, 3.1312348 , 3.13175956,\n",
       "       2.83760075, 2.3784047 , 3.07963485, 2.61950689, 3.06099973,\n",
       "       3.41438815, 3.18707399, 1.95292451, 2.65676249, 2.33897243,\n",
       "       3.0241906 , 2.30983502, 3.26163907, 4.15573698, 3.43387996,\n",
       "       3.04948579, 3.09341531, 2.68657053, 2.37899298, 2.30113767,\n",
       "       2.72039787, 2.87271332, 2.89117551, 3.19381648, 2.50575478,\n",
       "       3.02274874, 3.53723833, 2.60895275, 3.1331373 , 1.69937392,\n",
       "       1.6082256 , 3.23425577, 2.22044498, 2.32102107, 2.59750599,\n",
       "       2.73579723, 3.03416628, 2.33675188, 2.84553685, 3.04260437,\n",
       "       3.17799136, 3.00180058, 2.26475466, 2.96723983, 2.97096635,\n",
       "       2.64169306, 3.28258201, 3.03116268, 2.75419855, 2.496665  ,\n",
       "       2.63718241, 3.37443081, 3.16231293, 2.62770165, 2.87930038,\n",
       "       3.63666991, 3.17485242, 2.93538562, 2.90545435, 3.0522053 ,\n",
       "       2.3006813 , 3.1613111 , 2.89255539, 2.5728549 , 1.74914992,\n",
       "       3.23002612, 2.44731867, 2.99347225, 3.09805403, 2.61269661,\n",
       "       3.08752271, 3.9699133 , 2.39189928, 3.48035778, 2.25329089,\n",
       "       2.81037823, 2.53786799, 2.46644036, 2.70730755, 2.34179799,\n",
       "       2.62722687, 2.74121411, 2.33578965, 2.82197084, 2.34606951,\n",
       "       2.71535   , 2.72967185, 3.66611194, 2.69718533, 2.64739388,\n",
       "       2.56900438, 3.23062845, 3.59108858, 2.4027392 , 2.23249218,\n",
       "       2.9404031 , 3.00793967, 1.92251897, 2.82535926, 3.39845051,\n",
       "       3.15644251, 2.41138464, 2.92281914, 3.93556739, 2.50593023,\n",
       "       3.03282754, 3.33831108, 2.76435263])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
